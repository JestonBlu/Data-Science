<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data Science Tasks</title>
  <meta name="description" content="Data Science and Statistical Analysis I want to remember">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Data Science Tasks" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://github.com/jestonblu/datascience" />
  
  <meta property="og:description" content="Data Science and Statistical Analysis I want to remember" />
  <meta name="github-repo" content="jestonblu/datascience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science Tasks" />
  
  <meta name="twitter:description" content="Data Science and Statistical Analysis I want to remember" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="basic-random-forest.html">
<link rel="next" href="ensemble-model.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science Tasks</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="" data-path="statistical-methods.html"><a href="statistical-methods.html"><i class="fa fa-check"></i>Statistical Methods</a><ul>
<li class="chapter" data-level="" data-path="fitting-distributions.html"><a href="fitting-distributions.html"><i class="fa fa-check"></i>Fitting Distributions</a><ul>
<li class="chapter" data-level="" data-path="fitting-distributions.html"><a href="fitting-distributions.html#continuous-distributions"><i class="fa fa-check"></i>Continuous Distributions</a></li>
<li class="chapter" data-level="" data-path="fitting-distributions.html"><a href="fitting-distributions.html#discrete-distributions"><i class="fa fa-check"></i>Discrete Distributions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i>Hypothesis Testing</a></li>
<li class="chapter" data-level="" data-path="parameter-estimation.html"><a href="parameter-estimation.html"><i class="fa fa-check"></i>Parameter Estimation</a></li>
<li class="chapter" data-level="" data-path="sample-size-and-power.html"><a href="sample-size-and-power.html"><i class="fa fa-check"></i>Sample Size and Power</a><ul>
<li class="chapter" data-level="" data-path="sample-size-and-power.html"><a href="sample-size-and-power.html#proportions"><i class="fa fa-check"></i>Proportions</a></li>
<li class="chapter" data-level="" data-path="sample-size-and-power.html"><a href="sample-size-and-power.html#t-test"><i class="fa fa-check"></i>T-test</a></li>
<li class="chapter" data-level="" data-path="sample-size-and-power.html"><a href="sample-size-and-power.html#chi-square"><i class="fa fa-check"></i>Chi-square</a></li>
<li class="chapter" data-level="" data-path="sample-size-and-power.html"><a href="sample-size-and-power.html#anova"><i class="fa fa-check"></i>ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="survival-analysis.html"><a href="survival-analysis.html"><i class="fa fa-check"></i>Survival Analysis</a></li>
<li class="chapter" data-level="" data-path="experimental-design.html"><a href="experimental-design.html"><i class="fa fa-check"></i>Experimental Design</a><ul>
<li class="chapter" data-level="" data-path="experimental-design.html"><a href="experimental-design.html#completely-random-design"><i class="fa fa-check"></i>Completely Random Design</a></li>
<li class="chapter" data-level="" data-path="experimental-design.html"><a href="experimental-design.html#random-complete-block-design"><i class="fa fa-check"></i>Random Complete Block Design</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i>Contingency Tables</a></li>
<li class="chapter" data-level="" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i>Principal Components</a></li>
<li class="chapter" data-level="" data-path="eigen-values-and-statistical-distance.html"><a href="eigen-values-and-statistical-distance.html"><i class="fa fa-check"></i>Eigen Values and Statistical Distance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="regression-methods.html"><a href="regression-methods.html"><i class="fa fa-check"></i>Regression Methods</a><ul>
<li class="chapter" data-level="" data-path="matrix-regression.html"><a href="matrix-regression.html"><i class="fa fa-check"></i>Matrix Regression</a></li>
<li class="chapter" data-level="" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i>Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i>Poisson Regression</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="clustering-methods.html"><a href="clustering-methods.html"><i class="fa fa-check"></i>Clustering Methods</a><ul>
<li class="chapter" data-level="" data-path="kmeans-clustering.html"><a href="kmeans-clustering.html"><i class="fa fa-check"></i>Kmeans Clustering</a></li>
<li class="chapter" data-level="" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i>Hierarchical Clustering</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="forecasting.html"><a href="forecasting.html"><i class="fa fa-check"></i>Forecasting</a><ul>
<li class="chapter" data-level="" data-path="basic-graphical-methods-for-time-series.html"><a href="basic-graphical-methods-for-time-series.html"><i class="fa fa-check"></i>Basic Graphical Methods for Time Series</a></li>
<li class="chapter" data-level="" data-path="generate-time-series-data.html"><a href="generate-time-series-data.html"><i class="fa fa-check"></i>Generate Time Series Data</a><ul>
<li class="chapter" data-level="0.0.1" data-path="generate-time-series-data.html"><a href="generate-time-series-data.html#manually-generated-series"><i class="fa fa-check"></i><b>0.0.1</b> Manually Generated Series</a></li>
<li class="chapter" data-level="" data-path="generate-time-series-data.html"><a href="generate-time-series-data.html#auto-generated-series"><i class="fa fa-check"></i>Auto Generated Series</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i>Machine Learning</a><ul>
<li class="chapter" data-level="" data-path="basic-random-forest.html"><a href="basic-random-forest.html"><i class="fa fa-check"></i>Basic Random Forest</a></li>
<li class="chapter" data-level="" data-path="gradient-boosting.html"><a href="gradient-boosting.html"><i class="fa fa-check"></i>Gradient Boosting</a></li>
<li class="chapter" data-level="" data-path="ensemble-model.html"><a href="ensemble-model.html"><i class="fa fa-check"></i>Ensemble Model</a></li>
<li class="chapter" data-level="" data-path="overfitting.html"><a href="overfitting.html"><i class="fa fa-check"></i>Overfitting</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i>Simulation</a><ul>
<li class="chapter" data-level="" data-path="bootstrap-simulation.html"><a href="bootstrap-simulation.html"><i class="fa fa-check"></i>Bootstrap Simulation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="visualization.html"><a href="visualization.html"><i class="fa fa-check"></i>Visualization</a><ul>
<li class="chapter" data-level="" data-path="building-maps-with-choropleth-and-ggplot.html"><a href="building-maps-with-choropleth-and-ggplot.html"><i class="fa fa-check"></i>Building Maps with choropleth and ggplot</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Tasks</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="gradient-boosting" class="section level2 unnumbered">
<h2>Gradient Boosting</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## required packages
<span class="kw">library</span>(caret)
<span class="kw">library</span>(gbm)

## Training and Testing Data
hof.train =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/HOF_tr.csv&quot;</span>);
hof.test =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/HOF_te.csv&quot;</span>)

hof =<span class="st"> </span><span class="kw">rbind</span>(hof.train, hof.test)
hof<span class="op">$</span>HOF =<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">as.numeric</span>(hof<span class="op">$</span>HOF) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)

## create a training and testing set by randomly sampling from all of the data
## using the same set as in the random forest example
<span class="kw">set.seed</span>(<span class="dv">1002</span>)
x =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">nrow</span>(hof), <span class="dt">replace =</span> <span class="ot">FALSE</span>)

## remove unwanted columns
hof =<span class="st"> </span>hof[, <span class="op">-</span><span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">4</span>)]

## lets train the model on about 90% of the data
train =<span class="st"> </span>hof[x[<span class="dv">1</span><span class="op">:</span><span class="dv">900</span>], ]
test =<span class="st"> </span>hof[<span class="op">-</span>x[<span class="dv">1</span><span class="op">:</span><span class="dv">900</span>], ]

<span class="kw">head</span>(train)</code></pre></div>
<pre><code>    HOF POS  ASG    G   AB    R    H  DB TP  HR  RBI  SB  CS  BB   SO AVG
453   0  1B 0.44 2071 7030 1105 1921 295 48 370 1274  63  31 943 1137 273
803   0  SS 0.00  568 1104  142  260  43 10  37  109   7   5  94  220 236
621   0   C 0.00  476 1125   89  267  41  5  18  108   1   0  43  159 237
230   0  OF 0.12 1912 6787  926 1884 334 69 164  824 312 134 468 1266 278
379   0  OF 0.17 1457 4843  737 1399 212 60 142  661  89  68 644  591 289
720   0  OF 0.09 1221 3895  540 1020 175 37 112  485  45  30 351  574 262
    SLG OBP
453 487 359
803 393 304
621 331 268
230 420 325
379 445 371
720 412 323</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(train)</code></pre></div>
<pre><code> HOF     POS           ASG               G                AB       
 0:861   1B: 96   Min.   :0.0000   Min.   : 140.0   Min.   :  252  
 1: 39   2B:105   1st Qu.:0.0000   1st Qu.: 937.5   1st Qu.: 2628  
         3B:100   Median :0.0000   Median :1286.0   Median : 4034  
         C :158   Mean   :0.1028   Mean   :1338.3   Mean   : 4335  
         OF:331   3rd Qu.:0.1500   3rd Qu.:1666.2   3rd Qu.: 5607  
         SS:110   Max.   :0.9500   Max.   :3308.0   Max.   :12364  
       R                H                DB              TP        
 Min.   :  20.0   Min.   :  48.0   Min.   :  6.0   Min.   :  0.00  
 1st Qu.: 308.5   1st Qu.: 660.2   1st Qu.:110.8   1st Qu.: 12.00  
 Median : 511.5   Median :1061.0   Median :180.0   Median : 24.00  
 Mean   : 574.8   Mean   :1159.5   Mean   :199.4   Mean   : 30.44  
 3rd Qu.: 756.0   3rd Qu.:1531.2   3rd Qu.:264.0   3rd Qu.: 41.00  
 Max.   :2295.0   Max.   :3771.0   Max.   :725.0   Max.   :177.00  
       HR              RBI               SB                CS        
 Min.   :  0.00   Min.   :  21.0   Min.   :   0.00   Min.   :  0.00  
 1st Qu.: 37.75   1st Qu.: 280.5   1st Qu.:  15.00   1st Qu.: 15.00  
 Median : 81.00   Median : 447.0   Median :  40.50   Median : 30.00  
 Mean   :115.15   Mean   : 540.9   Mean   :  84.33   Mean   : 41.81  
 3rd Qu.:155.00   3rd Qu.: 708.0   3rd Qu.: 101.25   3rd Qu.: 57.00  
 Max.   :755.00   Max.   :2297.0   Max.   :1406.00   Max.   :335.00  
       BB               SO              AVG             SLG       
 Min.   :  17.0   Min.   :  35.0   Min.   :161.0   Min.   :222.0  
 1st Qu.: 226.8   1st Qu.: 375.5   1st Qu.:248.0   1st Qu.:351.0  
 Median : 363.0   Median : 569.0   Median :262.0   Median :392.5  
 Mean   : 435.3   Mean   : 643.5   Mean   :261.3   Mean   :393.2  
 3rd Qu.: 567.0   3rd Qu.: 841.2   3rd Qu.:274.0   3rd Qu.:432.0  
 Max.   :2190.0   Max.   :2597.0   Max.   :338.0   Max.   :565.0  
      OBP       
 Min.   :203.0  
 1st Qu.:310.0  
 Median :327.0  
 Mean   :328.2  
 3rd Qu.:347.0  
 Max.   :417.0  </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## build model
fitControl =<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedCV&quot;</span>, <span class="dt">number =</span> <span class="dv">5</span>, <span class="dt">repeats =</span> <span class="dv">5</span>)
mdl =<span class="st"> </span><span class="kw">train</span>(HOF <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train, <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>, <span class="dt">trControl =</span> fitControl,
            <span class="dt">verbose =</span> <span class="ot">FALSE</span>)

## Model Summary
mdl; <span class="kw">plot</span>(mdl)</code></pre></div>
<pre><code>Stochastic Gradient Boosting 

900 samples
 17 predictor
  2 classes: &#39;0&#39;, &#39;1&#39; 

No pre-processing
Resampling: Cross-Validated (5 fold, repeated 5 times) 
Summary of sample sizes: 720, 720, 720, 719, 721, 720, ... 
Resampling results across tuning parameters:

  interaction.depth  n.trees  Accuracy   Kappa    
  1                   50      0.9842196  0.7910195
  1                  100      0.9839986  0.7934159
  1                  150      0.9835517  0.7899395
  2                   50      0.9859986  0.8179582
  2                  100      0.9846653  0.8038399
  2                  150      0.9840035  0.7949731
  3                   50      0.9833307  0.7767886
  3                  100      0.9824443  0.7725392
  3                  150      0.9831146  0.7844066

Tuning parameter &#39;shrinkage&#39; was held constant at a value of 0.1

Tuning parameter &#39;n.minobsinnode&#39; was held constant at a value of 10
Accuracy was used to select the optimal model using  the largest value.
The final values used for the model were n.trees = 50, interaction.depth
 = 2, shrinkage = 0.1 and n.minobsinnode = 10.</code></pre>
<p><img src="05-Machine-Learning_files/figure-html/d1-1.png" width="864" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x =<span class="st"> </span><span class="kw">predict</span>(mdl, test, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)

## compile results
results =<span class="st"> </span><span class="kw">data.frame</span>(
  <span class="dt">Actual =</span> test<span class="op">$</span>HOF,
  <span class="dt">Prob.N =</span> x[, <span class="dv">1</span>],
  <span class="dt">Prob.Y =</span> x[, <span class="dv">2</span>]
)

## code 0/1 back to N/Y
results<span class="op">$</span>Actual =<span class="st"> </span><span class="kw">as.character</span>(results<span class="op">$</span>Actual)
results<span class="op">$</span>Actual[results<span class="op">$</span>Actual <span class="op">==</span><span class="st"> &#39;0&#39;</span>] =<span class="st"> &#39;N&#39;</span>
results<span class="op">$</span>Actual[results<span class="op">$</span>Actual <span class="op">==</span><span class="st"> &#39;1&#39;</span>] =<span class="st"> &#39;Y&#39;</span>
results<span class="op">$</span>Actual =<span class="st"> </span><span class="kw">factor</span>(results<span class="op">$</span>Actual)

## if probability of HOF is &gt; .5 then score a Y
results<span class="op">$</span>Prediction =<span class="st"> &quot;N&quot;</span>
results<span class="op">$</span>Prediction[results<span class="op">$</span>Prob.Y <span class="op">&gt;=</span><span class="st"> </span>.<span class="dv">5</span>] =<span class="st"> &quot;Y&quot;</span>
results<span class="op">$</span>Prediction =<span class="st"> </span><span class="kw">factor</span>(results<span class="op">$</span>Prediction)

## accuracy calculation from the random forest example
metric =<span class="st"> </span><span class="cf">function</span>(confusion) {
  sensitivity =<span class="st"> </span>confusion[<span class="dv">4</span>] <span class="op">/</span><span class="st"> </span>(confusion[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>confusion[<span class="dv">4</span>])
  specificity =<span class="st"> </span>confusion[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>(confusion[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>confusion[<span class="dv">3</span>])
  score =<span class="st"> </span>(sensitivity <span class="op">+</span><span class="st"> </span>(<span class="dv">3</span> <span class="op">*</span><span class="st"> </span>specificity)) <span class="op">/</span><span class="st"> </span><span class="dv">4</span>
  <span class="kw">return</span>(score)
}

## confusion matrix and accuracy score
(<span class="dt">confusion =</span> <span class="kw">table</span>(<span class="dt">Prediction =</span> results<span class="op">$</span>Prediction, <span class="dt">Actual =</span> results<span class="op">$</span>Actual))</code></pre></div>
<pre><code>          Actual
Prediction   N   Y
         N 106   2
         Y   0   8</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## accuracy score for training set
<span class="kw">metric</span>(confusion)</code></pre></div>
<pre><code>[1] 0.9861111</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## look at the incorrect responses and see if we can lower the threshold with creating
## false positives
<span class="kw">summary</span>(results); <span class="kw">subset</span>(results, Actual <span class="op">!=</span><span class="st"> </span>Prediction)</code></pre></div>
<pre><code> Actual      Prob.N             Prob.Y         Prediction
 N:106   Min.   :0.001712   Min.   :0.001282   N:108     
 Y: 10   1st Qu.:0.998683   1st Qu.:0.001317   Y:  8     
         Median :0.998683   Median :0.001317             
         Mean   :0.935894   Mean   :0.064106             
         3rd Qu.:0.998683   3rd Qu.:0.001317             
         Max.   :0.998718   Max.   :0.998288             </code></pre>
<pre><code>   Actual    Prob.N     Prob.Y Prediction
1       Y 0.9691392 0.03086077          N
78      Y 0.7711650 0.22883501          N</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">min.pred =<span class="st"> </span><span class="kw">min</span>(<span class="kw">subset</span>(results, Actual <span class="op">!=</span><span class="st"> </span>Prediction, <span class="st">&quot;Prob.Y&quot;</span>))

## it looks like there is no danger of lowering the threshold
results<span class="op">$</span>Prediction.new =<span class="st"> &quot;N&quot;</span>
results<span class="op">$</span>Prediction.new[results<span class="op">$</span>Prob.Y <span class="op">&gt;=</span><span class="st"> </span>min.pred] =<span class="st"> &quot;Y&quot;</span>

## confusion matrix and accuracy score
(<span class="dt">confusion =</span> <span class="kw">table</span>(<span class="dt">Prediction =</span> results<span class="op">$</span>Prediction.new, <span class="dt">Actual =</span> results<span class="op">$</span>Actual))</code></pre></div>
<pre><code>          Actual
Prediction   N   Y
         N 102   0
         Y   4  10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## accuracy score for training set
<span class="kw">metric</span>(confusion)</code></pre></div>
<pre><code>[1] 0.9285714</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## there are fewer incorrect answers, but the penalty for false positives are greater
## than false negatives so the accuracy score is actually lower</code></pre></div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basic-random-forest.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ensemble-model.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

<!-- </html> -->
